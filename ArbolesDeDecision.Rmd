---
title: "ArbolesDeDecision"
author: "Cristopher Barrios, Carlos Daniel Estrada"
date: "2023-03-10"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
librerias
```{r}
library(rpart)
library(rpart.plot)
library(dplyr) 
library(fpc) 
library(cluster) 
library("ggpubr") 
library(mclust)
library(caret)
library(tree)
library(randomForest)
library(plyr)
library("stats")
library("datasets")
library("prediction")
library(tidyverse)
```



### 1. Use los mismos conjuntos de entrenamiento y prueba que usó para los árboles de decisión en la hoja de trabajo anterior. 
```{r}
datos = read.csv("./train.csv")
test<- read.csv("./test.csv", stringsAsFactors = FALSE)
```

Lo Realizado anteriormente:

inciso 8:

```{r}
datos$clasificacion <- ifelse(datos$SalePrice > 290000, "Caras", ifelse(datos$SalePrice>170000, "Intemedia", "Economicas"))
clasificacion <- table(datos$clasificacion)
```

Inciso 4
```{r}
set_entrenamiento <- sample_frac(datos, .7)
set_prueba <-setdiff(datos, set_entrenamiento)


drop <- c("LotFrontage", "Alley", "MasVnrType", "MasVnrArea", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "Electrical", "FireplaceQu", "GarageType", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond", "PoolQC", "Fence", "MiscFeature")
set_entrenamiento <- set_entrenamiento[, !(names(set_entrenamiento) %in% drop)]
set_prueba <- set_prueba[, !(names(set_prueba) %in% drop)]
```

### 2. Elabore un árbol de regresión para predecir el precio de las casas usando todas las variables.


```{r}

arbol_2 <- rpart(clasificacion ~ ., data = set_entrenamiento)

```

```{r}
prp(arbol_2, main="Arbol de Regresion", nn=TRUE, fallen.leaves = TRUE, shadow.col = "green", branch.lty = 3, branch = .5, faclen = 0, trace = 1, split.cex = 0.8, split.box.col = "lightblue", split.border.col = "blue", split.round = 0.5)
```


```{r}
arbol_3 <- rpart(SalePrice ~ ., data = set_entrenamiento)
```

```{r}
prp(arbol_3, main="Arbol de Regresion", nn=TRUE, fallen.leaves = TRUE, shadow.col = "green", branch.lty = 3, branch = .5, faclen = 0, trace = 1, split.cex = 0.8, split.box.col = "lightblue", split.border.col = "blue", split.round = 0.5)
```


--modelo del arbol de decision
```{r}
#arbolModelo1 <- rpart(SalePrice~.,set_prueba,method = "class")
#rpart.plot(arbolModelo1)
```

--graficar arbol
```{r}

```





### 3. Úselo para predecir y analice el resultado. ¿Qué tal lo hizo? 

### 4. Haga, al menos, 3 modelos más cambiando el parámetro de la profundidad del árbol. ¿Cuál es el mejor modelo para predecir el precio de las casas? 

### 5. Compare los resultados con el modelo de regresión lineal de la hoja anterior, ¿cuál lo hizo mejor? 

### 6. Dependiendo del análisis exploratorio elaborado cree una variable respuesta que le permita clasificar las casas en Económicas, Intermedias o Caras. Los límites de estas clases deben tener un fundamento en la distribución de los datos de precios, y estar bien explicados  

### 7. Elabore  un  árbol  de  clasificación  utilizando  la  variable  respuesta que  creó  en  el  punto anterior.  Explique los resultados a los que llega. Muestre el modelo gráficamente. Recuerde que la nueva variable respuesta es categórica, pero se generó a partir de los precios de las casas, no incluya el precio de venta para entrenar el modelo. 

### 8. Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar.

### 9. Haga un análisis de la eficiencia del algoritmo usando una matriz de confusión para el árbol de clasificación. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores. 

### 10. Entrene un modelo usando validación cruzada, prediga con él. ¿le fue mejor que al modelo anterior? 

### 11.  Haga al menos, 3 modelos más cambiando la profundidad del árbol. ¿Cuál funcionó mejor? 

### 12. Repite los análisis usando random forest como algoritmo de predicción, explique sus resultados comparando ambos algoritmos.  